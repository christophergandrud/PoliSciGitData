%%%%%%%%%%%%%%%%%%
% GitHub: Putting the social in social science data set development and verification
% Christopher Gandrud
% 11 January 2013
%%%%%%%%%%%%%%%%%

% !Rnw weave = knitr

\documentclass[twocolumn]{article}
\usepackage{fullpage}
\usepackage[authoryear]{natbib}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=cyan,
    urlcolor=cyan
}
\usepackage{dcolumn}
\usepackage{booktabs}
\usepackage{url}
\usepackage{tikz}
\usepackage{todonotes}
\usepackage[utf8]{inputenc} 

%%%%%%% Title Page %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{GitHub: Putting the social in social science data set development and verification}

\author{Christopher Gandrud \\
                {\emph{Yonsei University}}\footnote{Email: \href{mailto:gandrud@yonsei.ac.kr}{gandrud@yonsei.ac.kr}. I discuss the ideas from this article in much more detail in my forthcoming book ``Reproducible Research with R and RStudio" (Chapman and Hall).}} 

\begin{document}

\maketitle

\begin{quote}
  \emph{I can't send you my data b/c I think you might find out I made an error. \#overlyhonestmethods  (tweeted by Charlisle Rainey, 1/10/2013)}
\end{quote}

A data set is created, analyses are run, an article is published, the data set languishes. The researchers who create the data set move on to other projects. Maybe someone else is able to access the data and they update part of it for their own work, but the original is not changed and the updates not widely known about. Maybe another researcher finds a mistake in the original data set. They email the original authors suggesting corrections. The original authors may or may not make the changes. Some researchers may even be reluctant to make their data available at all because of a fear that someone may find a mistake in it. These are all examples of ways that the development and management of social science data sets do not take advantage of knowledge distributed in the social science community. These problems are partially caused by the data storage tools social sciencist use. Despite rapid recent advances in social technologies--Twitter, Facebook, Skype, and so on--the tools many social scientists use do not make it easy to collaboratively develop and verify data sets, especially for people not involved in creating the original data.

In this brief article I show that GitHub\footnote{https://github.com/} offers a comprehensive data storage service for social scientists with unique tools for \emph{social data set development and verification}, i.e. correcting errors. GitHub also fits directly into a highly reproducible workflow, particularly one that also includes R.\footnote{GitHub can be used to store and develop entire social science research projects, not just data. However, I do not directly address these other topics here.}

GitHub was originally created and is widely used as a tool for software developers to work together on software projects using the Git\footnote{\url{http://git-scm.com/}} version control system. Though GitHub is often used by social scientists for statistical package development\footnote{For example the \emph{Zelig} R package \citep{Zelig2008,R-zelig} is now hosted on GitHub. See \url{https://github.com/IQSS/Zelig}.} it seems strange to suggest that this service would be useful for social scientists for building and maintaining data sets. However, a software program and many social science data sets are fundamentally similar. They are basically just collections of text files. GitHub is just a means of storing and version controlling text files. So if a social scientist's data is in a plain-text format, such as comma-separated values (CSV) for quantitatitve data,\footnote{All major statistical programs as well as Microsoft Excel and Apple's Numbers can save and open files in plain-text formats like CSV.} and has accompanying files variable description files also in a plain text format--e.g. TXT plain text or Markdown (MD), then they can take full advantage of GitHub's features for social collaboration and verification.\footnote{See \citeaurthor{Bowers2011} \citep[3]{Bowers2011} for a discussion of the advantages of storing research files in plain-text format.}

In this article I first discuss basic features that we would want from a cloud service to store social science data: stable storage, access, version control, and collaboration. Then I discuss how strong these features are in three methods currenlty used to store data in social science. Though they each have their strengths none of them encourages social data set development and verification.

A few brief notes before getting started: To set up Git andGitHub see the GitHub page: \url{https://help.github.com/articles/set-up-git}. In this article I give examples thei GitHub website and from the command line. However, there are also very good graphical user interface (GUI) versions of GitHub for Mac and Windows (see the set up page). I focus on GitHub, but you can also use other services that work with Git such as Bitbucket\footnote{\url{https://bitbucket.org/}} for many of the same functions. Finally, the methods I use in this article are suitable for small to medium size data sets (i.e. of about 100,000 observations or less) common in social science. Much larger data sets often cannot be efficiently stored in plain-text files, so GitHub is probably not a suitable storage service for them.

\section{What do we need from cloud data storage?}

A cloud storage service for social science data needs to enable at least four things: \emph{stable storage}, \emph{access}, \emph{version control}, and \emph{collaboration}. Obviously a cloud storage service needs to be a stable and reliable platform for keeping data sets on. Data stored on it needs to be accessible to both collaborators and people who wish to reproduce an analysis \citep{Fomel2009} or use the data set in a new project \citep{Kelly2006,King1995}. Another key part of access is that the data set, both developement and use, can be easily tied into researchers' workflows. The service needs to include version control--similar to track changes in a word processing program--so that the development of the data set can be understood and researchers are able to revert to old versions. See \cite{Bowers2011}, \cite{Healey2011} and \cite{Fredrickson2011} for discussions of the importance of version control. Finally, a cloud data storage service should make collaboration easy. Collaboration should not be limited to coauthors. It should be possible to collaborate with non-coauthors to take advantage of knowledge (and motivation) distributed throughout the social science community. Ideally, social data set development and verification will keep data sets more up-to-date and more accurate. 

\section{Data storage: the social science status quo}

Social science data is often stored in at least three ways. It may be stored locally on a researcher's computer, on a general purpose cloud storage service such as Dropbox\footnote{\url{https://www.dropbox.com/}} or Google Cloud Drive,\footnote{\url{https://drive.google.com/}} or data may be stored on a specialized research hosting service, notably Dataverse.\footnote{\url{http://thedata.org/}} Each of these data storage methods have their strengths in terms of stable storage, access, version control, and collaboration. Nontheless each are lacking in at least one important way and none of them promote social data development and verification.

\paragraph{Local storage}

The least robust form of data storage currently used, is only storing data on an individual researcher's computer. This is not a very stable form of storage as anyone that has lost all of their files when their computer died knows. The research with access to the computer can easily access the data and use it in their workflow, but access from other computers and for coathors can be limited. Access by non-coauthors is very combersome. Files must be emailed in response to individual requests. These files are not automatically updated with new versions of the data. Version control with Git or some other program is possible with locally stored data. Because access is limited to users of the computer the data is stored on, collaboration, especially by non-coauthors is extremely limited.

\paragraph{General purpose cloud storage}

Dropbox and other non-Git cloud storage service offer a much more robust form of storage. These services generally work by syncing files stored on individual computers with those on cloud servers. Access is also much better. These services usually can be accessed via desktop programs, mobile apps, and websites. Because files stored on individual computers are automatically synced with the cloud serves it is very easy to incorporate them into a workflow. General purpose cloud storage services also make it possible to share files and folders via URL links. Dropbox has a basic version control system. Everytime you save a file a version is saved on Dropbox. If you are using Dropbox for free old versions are only saved for 30 days.\footnote{Old versions are stored for longer with paid accounts.} In addition you could use Git with a data set stored on Dropbox. Collaboration with coauthors is very easy because folders can be shared. This means that official collaborators (those given write access to the folder) can easily make changes to files in the folder and these changes are automatically synced for all users.\footnote{This can create problems if multiple authors are making changes to the same files at the same time. For a discussion of file conflicts see \citep{Fredrickson2011}.} However noncoauthors, without write access to the shared folder cannot easily make changes. They must email one of the researchers with write access to suggest updates.

\paragraph{Dataverse}

Many journals--Political Analysis for example--require data used in articles they publish to be uploaded to a service like Dataverse. Dataverse is a stable form of storage that is easily accessible for anyone with an internet connection. The standard version of Dataverse however, difficult to incorporate Dataverse into a research workflow.\footnote{It is possible to build a custom version of Dataverse with R integration.} Unlike Dropbox, for example, there is no way to automatically update a data set on Dataverse. You have to point and click to upload data files for each version. It is difficult to access data through a statistical program such as Stata or R. The data needs to be downloaded by pointing and clicking and then loaded into these programs. It does have some version control features. It saves each version that is uploaded. Finally it is difficult to collaborate using Dataverse. Changes to a data set must be uploaded to the site manually, then manually downloaded. There are also no direct ways for non-coauthors to suggest changes.

Dataverse is good for what it is designed to do: store a snapshot of a data set for replicating specific published results. However, it is difficult to use it to store and access data as part of an ongoing workflow and it does not enable social data set development and verification.

\section{Data on GitHub}

GitHub can meet the four criteria for data set storage. In this section I will demonstrate how to use GitHub for data set storage, version control, access, and collaboration. I focus specifically on specific particularly important aspects of each feature rather than providing a complete overview of how to use Git and GitHub. In this section I refer to a data set stored on GitHub of countries' Gallagher Electoral Disproportionality index that I compiled \citep[see][]{Gallagher1991,Carey2011}. The data set and more information is avalialble at: \url{http://christophergandrud.github.com/Disproportionality_Data/}.

\subsection{Storing and Version control}

Version control is an integral part of how GitHub stores files. GitHub remotely stores files in what Git terms ``repositories", repos for short. You can think of repos as parent folders for a data set. They would contain the data and description files. Git version controls these files and GitHub hosts these folders remotely in the cloud.\footnote{Specifically, GitHub files are stored on Rackspace (\url{http://www.rackspace.com/}).} 

It is free to store files on GitHub as long as they are in what GitHub calls public repositories. Anyone can see the contents of public repositories, including all previous versions.\foonote{Private repositories are available that allow only official contributors to see them. These require a paid account.} Users can have unlimited public repositories There is a soft storage size limit of one gigabyte per repository. This should be more than enough for most social science data sets if they are stored in plain-text formats. Here is a portion of the electoral disproporationality repository's main page:

\includegraphics[width=0.46\textwidth]{images/MainPage.png}

Git is a very powerful version control system, especially for text files. For these types of files, rather than saving the whole file like Dropbox and Dataverse, Git only saves the actual changes when you \texttt{add} a file to the repository and then \texttt{commit} a version of the file to the repository. Each commit in a repo is given a unique SHA-1 number identifiying it. Once changes made on your computer are commited they can be ``pushed" to the remote GitHub version of the repo. A repo's GitHub website allows you to view all of the changes that have been made to it.

\paragraph{Version Control \& Contributor analytics}

An important component of version control for GitHub for us here is that because Git only saves changes and it uniquely identifies who the changer is, it is possible to properly attribute every individuals contribution to a data set. GitHub has analytic capabilaties for organizing this data. You can find these by clicking on the \texttt{Graphs} button located near the top of each repository. This will give you access to graphs such as the one below (I've blurred the contributors names):

\includegraphics[width=0.46\textwidth]{images/CommitHistory.png}

\paragraph{Binary files}

I mentioned that non-plain-text files--binary files--such like those Stata uses to store data are treated differently. Rather than only the specific changes being saved with each commit, the entire file is stored again. If the files are very very large this could take up a lot of storage space, though it is important to remember that pervious commits are commpressed. This is also a problem for all of the other data storage methods with version control discussed here. For very large data sets you will need to use a totally different cloud storage system like Rackspace or Amazon's S3.\footnote{\url{http://aws.amazon.com/s3/}} You will also not be able to get the sort of granualar contributor data for binary files that you do for text files. 

If you absolutely must have binary files in a repository one solution to the space constraints problem is to have Git ignore it. You do this by including a text file called \texttt{.gitignore}  in your repository. In .gitignore simply type the binary file's name. Git will not version control it. This unfortuantely means that it will not be loaded on to GitHub when you push your files.

\paragraph{Describe the data set with README files}

Each folder in a GitHub repository can contain a files called README.\footnote{Actually each folder in a repository can contain one as well.} README files for data sets can contain information data source, variable descriptions, and so on, that would be useful for understanding it. GitHiub automatically displays the README file. If it is written in the Git Flavored Markdown\footnote{http://github.github.com/github-flavored-markdown/} markup language and called README.md it will also be automatically formatted. You can see part of the disproportionality data set's README.md above. 

\paragraph{Tagging versions}

Git \texttt{tag}s function as bookmarks for major versions of a Git repository. They are particularly useful for demarcating the version of a data set used in a particular publication, for example. creating tags is simple. Imagine we want to tag the second major version of a data set, the one we used for a publication:

<<TagCreate, eval=FALSE, engine='sh'>>=
git tag -a v2 -m 'version used in CITE'
@

\noindent The command option \texttt{-a} means add, \texttt{v2} is the version number, and \texttt{-m} adds a message, in this case the publication publications citation information. Then simply \texttt{push} the tags to GitHub:

<<PushTage, eval=FALSE, engine='sh'>>=
git push --tags
@

\noindent Now on GitHub there will be a list with the tag and an option to view and download that specific version of the data. For example:

\includegraphics[width=0.47\textwidth]{images/GitTag.png}

\subsection{Accessing data}

There are many ways to access data stored on GitHub and incorporate it into your workflow. The simplest way is to use the GitHub website to actually edit files and commit changes. This can be handy for small changes and accessing the data from mobile devices. As I mentioned, changes can be committed on your computer and pushed to GitHub. You can use the command line version of Git or the GUI version of GitHub also. RStudio,\footnote{\url{http://www.rstudio.com/}} a program that strongly strong integrates R and markup languages like \LaTeX and Markdown, also includes Git. Here is a screenshot of this paper being written in RStudio. You can see the Git functions in the upper right. So it is possible to make changes to a repository, commit them and push them to GitHub all within the same program.

\includegraphics[width=0.46\textwidth]{images/RStudio.png}

\paragraph{Cloning a repo}

Repositories can be downloaded in full. This is called cloning. You can do this by clicking the \texttt{Clone in . . .} button on the GitHub repositories' website. It can also be done in the command line using the repository's address. For example, the disproportionality data's clonable address is: \url{https://github.com/christophergandrud/Disproportionality_Data.git}. 

{\small
<<Clone, eval=FALSE, engine='sh'>>=
git clone https://github.com/christophergandrud/
  Disproportionality_Data.git
@
}

\noindent Note that in real life the adderss needs to be on the same line. Also remember to change the working directory to the place where you want to have the repo saved using the \texttt{cd} command before cloning it.

Once you have cloned the repository you can role back to any previous version with the \texttt{checkout} command. For example if you wanted to role back to a tag called ``v3":

<<Checkout, eval=FALSE, engine='sh'>>=
git checkout v3
@

\paragraph{Access data directly from R}

Loading data stored on GitHub into R for use in statistical analysis is very easy. I have created a function that loads plain-text formatted data from GitHub into an R data frame.\footnote{The function is based on \emph{devtools}' \texttt{source\_url} command.} It's called \verb|source_GitHubData| and is stored in a GitHub Gist\footnote{Gists host code snypests. See \url{https://gist.github.com/}.} at: \url{https://gist.github.com/4466237}. It can be loaded into R using the \verb|source_gist| command from the \emph{devtools} package \citep{R-devtools}.

<<LoadGist, message=FALSE, tidy=FALSE>>=
# Load source_GitHubData
# The functions' gist ID is 4466237
devtools::source_gist("4466237")
@

\noindent The main argument in \texttt{source\_GitHubData} is the \texttt{url}. You just set this as the URL for the \emph{raw} version of data file you want to download. The raw version is the version with only the text-file (no extra HTML markup). You get this by clicking on the the file's GitHub page: 

\includegraphics[width=0.4\textwidth]{images/Raw.png}

The raw URL for each commit and tagged versions of the data are also accessible if you want to always link to the same version of the file. The URL for the raw version of the electoral disproportionality data is \url{http://bit.ly/Ss6zDO}.\footnote{I used bitly (\url{http://bitly.com/}) to shorten the URL so that it would fit on the page more easily. The full URL is: \url{https://raw.github.com/christophergandrud/Disproportionality_Data/master/Disproportionality.csv}.}  To download the data using \verb|source_GitHubData| simply type.

<<DispropDownload, message=FALSE, tidy=FALSE>>=
# Download data
Data <- source_GitHubData(
          url = "http://bit.ly/Ss6zDO")
@

\noindent Note that by default \verb|source_GitHubData| loads CSV data. You can add the argument \verb|sep = "\t"| for tab-separated data files. You can also specify \texttt{header = TRUE} (default) or \texttt{header = FALSE}.

\paragraph{Citing GitHub data}

When a researcher uses data they accessed via GitHub how can they cite it? A common practice is to cite the publication the data set was originally used in. However, this is incomplete in at least two ways. First, the version of the data used in the original publication may be different from that used later on. Second, it would be difficult to use this citation to acknowledge contributions made by contributors who did not work on the original data set, but contributed to later versions. One solution is to use the standard set by \cite{Aitman2007}.\footnote{Dataverse uses a version of this standard.} They propose that data set citations should included:

\begin{itemize}
  \item the authors name, 
  \item date,
  \item data set title,
  \item a unique global identifier (UGI),
  \item a universal numeric fingerprint (UNF),
  \item a bridge service.
\end{itemize}

\noindent The first three are self explanatory and shared with standard citations for other types of materials. Examples of UGI include Document Object Identifiers (DOI) and the Handel System.\footnote{\url{http://www.handle.net/}} These are unique identifiers for the data set. UNF's is a unique number for a particular version of the data set. Finally a bridge service allows you to use the DOI and UNF to link to the actual data set. 

We can easily use \citeauthor{Aitman2007}'s citation standards for GitHub repositories. I would suggest citing specific tags of the data set. If these are not available you can cite the specific commit you used to produce results with the data.

\paragraph{Showcase a data set with GitHub Pages}

Each public repository's GitHub website allows anyone full access to the data. However, these pages may be confusing for those with out experience with a version control system. To solve this problem GitHub Pages\footnote{\url{http://pages.github.com/}} allows you to very easily create a simple webpage for the repository. These pages include links to download the entire repository. You can of course also add links with specific files.

To create your repository's page navigate to the repository's normal webpage. Then click \texttt{Settings} \textrightarrow{} \texttt{Automatic Page Generator}. By default it will load the README file as the content of the webpage. You can change this, add a Google Analytics tracking ID\footnote{\url{http://www.google.com/analytics/}} to gather information on who visits the page, and choose a style. Here is a sample of the disproportionality data's page:

\includegraphics[width=0.45\textwidth]{images/Pages.png}

\subsection{Collaboration}

Compared to the status quo social science data storage methods GitHub is uniquely strong for enabling collaboration both between coauthors and even non-coauthors who may may be able to help develope and verify the data set.  

\paragraph{Coauthors}

Public repositories can have an unlimited number of collaborators.\footnote{On the repositories' GitHub site click \texttt{Settings} \textrightarrow \texttt{Collaborators}} Collaborators have the same priveleges to make changes to the repository. They all do so in the same way. There is one important thing to note. If multiple collaborators are actively working on a data set they need to add an extra step to their Git workflow. They need to \texttt{pull} their collaborator's changes and resolve any conflicting files before pushing the changes to GitHub. Here is a full example:

<<Collaborate, eval=FALSE, engine='sh'>>=
# Add new files to Git
git add .

# Commit the changes
git commit -am "A message"

# Pull collaborator's commits
git pull

# Push changes to GitHub
git push origin master
@

\todo[inline]{Zachary, are you thinking of discussing some of these commands in more detail?}

\paragraph{Non-Coauthors: Pull requests}

People who want to make changes to a repository, but are not collaborators can make pull requests. All they need are GitHub accounts. Pull requests are basically specific changes to a file that someone suggests. Requesters can also include comments about why they are making the request. GitHub also has a discussion forumn to discuss these comments. It is then up to the repository's owners to decide whether or not to accept the requested changes. If they accept the changes, they are made instantly and a full record of who made the changes is kept.

If someone notices a small error--e.g. a misspelling, a misclassification--or other improvement that they think should be made to a data set they can make a pull request by navigating to the GitHub page for the specific file they think needs to be changed. Then they click \texttt{Edit}, which is located next to the \texttt{Raw} button (see above). Clicking this button ``forks" the repository, i.e. gives you a copy you can change. They will see a window like this:

\includegraphics[width=0.46\textwidth]{images/PullRequest.png}

\noindent In this window they can make their proposed changes and add a comment about what the changes are before clicking \texttt{Propose File Change}.

For longer file changes, for example if someone updates a data set, simply fork the data set's repository, by clicking the \texttt{Fork} button on the upper right corner of its webpage. They can then make changes to the forked repository as if it was their own. When they are ready to suggest the changes be included they can just click the \texttt{Pull Request} button at the top center of the forked repository. For more information on forking and pull requests see the GitHub article on the topic: \url{https://help.github.com/articles/using-pull-requests}.

\paragraph{Issues}

GitHub repositories also have an ``Issues" area that allows any other GitHub user to make a comment on the repo. These tend to include general suggests for how to improve the files or questions about the repo that may be of general interest. Anyone can respond in the Issues area.

\paragraph{Repo Wiki}

GitHub provides a very easy to use set of features for creating nicely formated repository wiki's. For a data set repo, short articles could be developed giving details about how a data set was created for example. Non-official collaborators can add to repo wikis. Like pull requests, their changes are subject to approval by one of the repository's owners.

\paragraph{Follow a repository}

If you are a GitHub member you can follow a public repository, even if you aren't a collaborator, This gives you a Facebook-style newsfeed\footnote{See \url{https://www.facebook.com/help/327131014036297/}.} where you can to see any updates that are made to the data set repository. 

\paragraph{Passing on the data set}

Because of changing time commitments, professional interests, and so on, no one can maintain and update a data set forever. GitHub makes it easy to pass on control of a data set while maintaining it's entire version history. Simply add a collaborator to the repository. Then enter the collaborator's GitHub username. They will then have the same privaleges to manage the repository as you did.

\paragraph{Selective incentives}

GitHub not only provides technology--particularly pull requests--for social data development and verification, but it also gives selective incentives that can add motivation to do so. Why would people actively contribute to improving publicly available data sets, especially those primarily associated with other authors? If a repository had many non-official contributors it would be impracticle to cite all of them whenever someone used the data set, for example. By keeping track of who made what changes and providing numerous ways to quantify and visualize each member's contribution GitHub provides strong selective incentives to collaborate. Perhaps one day social scientists could even use GitHubs descriptive statistics when they meet highering and promotion committees.   

\section{Conclusion}

In this article I have tried to show that GitHub is a very good option for storing social science data in the cloud. Admittadly it has more of a learning curve than the incumbent options. However, I hope to have demonstrated that it is at least as good as the alternatives in terms of stable storage, access, version control, and collaboration.  It is by far better at for enabling social data development and verification. Hopefully by using a service like GitHub that both makes collabotration easy and provides selective incentives to do so we can improve the social science community's ability to utilize its collective knowledge to have more complete and robust data sets with which to answer our questions.




\bibliographystyle{apsr}
\bibliography{PoliSciGitStore}

\end{document}